{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cfb1a86",
   "metadata": {},
   "source": [
    "# Fold 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8b9369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from UModel import UNet\n",
    "import torch\n",
    "import Config\n",
    "import dataloader\n",
    "import os\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torchvision.utils\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "filenames = []\n",
    "\n",
    "path = 'C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\output\\\\test_paths0.txt'\n",
    "\n",
    "lines = open(path,\"r\").read().split(\"\\n\")\n",
    "for line in lines:\n",
    "    filename = os.path.basename(line)\n",
    "    filenames.append(filename)\n",
    "    X_test.append(line)\n",
    "    y = 'C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\Masks\\\\'+filename\n",
    "    y_test.append(y)\n",
    "\n",
    "test_transform = A.Compose([A.Resize(Config.Input_Height, Config.Input_Width),\n",
    "                               A.Normalize(mean=(0.0), std=(1.0)),\n",
    "                               ToTensorV2()])\n",
    "testDS = dataloader.MyDataset(imagePaths=X_test, maskPaths=y_test, transform=test_transform)\n",
    "testLoader = DataLoader(testDS, shuffle=False, batch_size=1,\n",
    "                             pin_memory=Config.PIN_MEMORY)\n",
    "\n",
    "\n",
    "\n",
    "model= torch.load('C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\output\\\\unet_out.pth')\n",
    "model.eval()\n",
    "\n",
    "image_no = 0\n",
    "for x,y in testLoader:\n",
    "    x = x.to(Config.DEVICE)\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    preds = torch.argmax(softmax(model(x.float())), axis = 1).detach().cpu().numpy()\n",
    "    img = np.transpose(np.array(x[0,:,:,:].to('cpu')),(1,2,0))\n",
    "    preds = np.array(preds[0,:,:])\n",
    "#     mask = np.array(y[0,:,:])\n",
    "    cv2.imwrite('C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\output\\\\Fold 1\\\\'+filenames[image_no], preds)\n",
    "    image_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a24cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed Waleed\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ahmed Waleed\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Dice score: 0.46423081851791104\n",
      "Average IoU: 0.4062475920626941\n",
      "Average precision: 0.4836298240049254\n",
      "Average recall: 0.9751935130004546\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def iou(pred, gt):\n",
    "    intersection = np.sum((pred == 1) & (gt == 1))\n",
    "    union = np.sum((pred == 1) | (gt == 1))\n",
    "    if union == 0:\n",
    "        return 0\n",
    "    return intersection / union\n",
    "\n",
    "# ground truth masks and predictions are binary numpy arrays of shape (num_samples, height, width)\n",
    "gt_path = \"C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\Masks_800\"\n",
    "pred_path = \"C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\output\\\\Fold 1\"\n",
    "\n",
    "scores = {'filename': [], 'Dice score': [], 'IoU': [], 'precision': [], 'Recall': []}\n",
    "\n",
    "for file in os.listdir(pred_path):\n",
    "    if file.endswith('.PNG'):\n",
    "        filename = os.fsdecode(file)\n",
    "\n",
    "        y_true = cv2.imread(gt_path+'\\\\'+filename)\n",
    "        y_pred = cv2.imread(pred_path+'\\\\'+filename)\n",
    "        y_true_flat = y_true.reshape(-1)\n",
    "        y_pred_flat = y_pred.reshape(-1)\n",
    "\n",
    "#         target = torch.from_numpy(target)\n",
    "#         pred = torch.from_numpy(pred)\n",
    "\n",
    "        precision = precision_score(y_true_flat, y_pred_flat, average='macro')\n",
    "        recall = recall_score(y_true_flat, y_pred_flat, average='macro')\n",
    "        IoU = iou(y_pred_flat, y_true_flat)\n",
    "        dice = 2 * (y_true_flat * y_pred_flat).sum() / (y_true_flat.sum() + y_pred_flat.sum())\n",
    "        \n",
    "        scores['filename'].append(filename)\n",
    "        scores['Dice score'].append(dice)\n",
    "        scores['IoU'].append(IoU)\n",
    "        scores['precision'].append(precision)\n",
    "        scores['Recall'].append(recall)\n",
    "\n",
    "df = pd.DataFrame(scores)\n",
    "df\n",
    "average_f1_score = df['IoU'].mean()\n",
    "average_precision = df['precision'].mean()\n",
    "average_recall = df['Recall'].mean()\n",
    "average_dice = df['Dice score'].mean()\n",
    "\n",
    "print(\"Average Dice score:\", average_dice)\n",
    "print(\"Average IoU:\", average_f1_score)\n",
    "print(\"Average precision:\", average_precision)\n",
    "print(\"Average recall:\", average_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c43d881",
   "metadata": {},
   "source": [
    "# Fold 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69e37515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed Waleed\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] The specified procedure could not be found\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from UModel import UNet\n",
    "import torch\n",
    "import Config\n",
    "import dataloader\n",
    "import os\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torchvision.utils\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "filenames = []\n",
    "\n",
    "path = 'C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\output\\\\test_paths1.txt'\n",
    "\n",
    "lines = open(path,\"r\").read().split(\"\\n\")\n",
    "for line in lines:\n",
    "    filename = os.path.basename(line)\n",
    "    filenames.append(filename)\n",
    "    X_test.append(line)\n",
    "    y = 'C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\Masks\\\\'+filename\n",
    "    y_test.append(y)\n",
    "\n",
    "test_transform = A.Compose([A.Resize(Config.Input_Height, Config.Input_Width),\n",
    "                               A.Normalize(mean=(0.0), std=(1.0)),\n",
    "                               ToTensorV2()])\n",
    "testDS = dataloader.MyDataset(imagePaths=X_test, maskPaths=y_test, transform=test_transform)\n",
    "testLoader = DataLoader(testDS, shuffle=False, batch_size=1,\n",
    "                             pin_memory=Config.PIN_MEMORY)\n",
    "\n",
    "\n",
    "\n",
    "model= torch.load('C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\output\\\\unet_out.pth')\n",
    "model.eval()\n",
    "\n",
    "image_no = 0\n",
    "for x,y in testLoader:\n",
    "    x = x.to(Config.DEVICE)\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    preds = torch.argmax(softmax(model(x.float())), axis = 1).detach().cpu().numpy()\n",
    "    img = np.transpose(np.array(x[0,:,:,:].to('cpu')),(1,2,0))\n",
    "    preds = np.array(preds[0,:,:])\n",
    "#     mask = np.array(y[0,:,:])\n",
    "    cv2.imwrite('C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\output\\\\Fold 2\\\\'+filenames[image_no], preds)\n",
    "    image_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d16c8aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ahmed Waleed\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Dice score: 0.46738175179220953\n",
      "Average IoU: 0.4068015360401259\n",
      "Average precision: 0.48370703235007145\n",
      "Average recall: 0.9763429808803994\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def iou(pred, gt):\n",
    "    intersection = np.sum((pred == 1) & (gt == 1))\n",
    "    union = np.sum((pred == 1) | (gt == 1))\n",
    "    if union == 0:\n",
    "        return 0\n",
    "    return intersection / union\n",
    "\n",
    "# ground truth masks and predictions are binary numpy arrays of shape (num_samples, height, width)\n",
    "gt_path = \"C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\Masks_800\"\n",
    "pred_path = \"C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\output\\\\Fold 2\"\n",
    "\n",
    "scores = {'filename': [], 'Dice score': [], 'IoU': [], 'precision': [], 'Recall': []}\n",
    "\n",
    "for file in os.listdir(pred_path):\n",
    "    if file.endswith('.PNG'):\n",
    "        filename = os.fsdecode(file)\n",
    "\n",
    "        y_true = cv2.imread(gt_path+'\\\\'+filename)\n",
    "        y_pred = cv2.imread(pred_path+'\\\\'+filename)\n",
    "        y_true_flat = y_true.reshape(-1)\n",
    "        y_pred_flat = y_pred.reshape(-1)\n",
    "\n",
    "        precision = precision_score(y_true_flat, y_pred_flat, average='macro')\n",
    "        recall = recall_score(y_true_flat, y_pred_flat, average='macro')\n",
    "        IoU = iou(y_pred_flat, y_true_flat)\n",
    "        dice = 2 * (y_true_flat * y_pred_flat).sum() / (y_true_flat.sum() + y_pred_flat.sum())\n",
    "        \n",
    "        scores['filename'].append(filename)\n",
    "        scores['Dice score'].append(dice)\n",
    "        scores['IoU'].append(IoU)\n",
    "        scores['precision'].append(precision)\n",
    "        scores['Recall'].append(recall)\n",
    "\n",
    "df = pd.DataFrame(scores)\n",
    "df\n",
    "average_f1_score = df['IoU'].mean()\n",
    "average_precision = df['precision'].mean()\n",
    "average_recall = df['Recall'].mean()\n",
    "average_dice = df['Dice score'].mean()\n",
    "\n",
    "print(\"Average Dice score:\", average_dice)\n",
    "print(\"Average IoU:\", average_f1_score)\n",
    "print(\"Average precision:\", average_precision)\n",
    "print(\"Average recall:\", average_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa095ad",
   "metadata": {},
   "source": [
    "# Fold 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "811b97e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from UModel import UNet\n",
    "import torch\n",
    "import Config\n",
    "import dataloader\n",
    "import os\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torchvision.utils\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "filenames = []\n",
    "\n",
    "path = 'C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\output\\\\test_paths2.txt'\n",
    "\n",
    "lines = open(path,\"r\").read().split(\"\\n\")\n",
    "for line in lines:\n",
    "    filename = os.path.basename(line)\n",
    "    filenames.append(filename)\n",
    "    X_test.append(line)\n",
    "    y = 'C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\Masks\\\\'+filename\n",
    "    y_test.append(y)\n",
    "\n",
    "test_transform = A.Compose([A.Resize(Config.Input_Height, Config.Input_Width),\n",
    "                               A.Normalize(mean=(0.0), std=(1.0)),\n",
    "                               ToTensorV2()])\n",
    "testDS = dataloader.MyDataset(imagePaths=X_test, maskPaths=y_test, transform=test_transform)\n",
    "testLoader = DataLoader(testDS, shuffle=False, batch_size=1,\n",
    "                             pin_memory=Config.PIN_MEMORY)\n",
    "\n",
    "\n",
    "\n",
    "model= torch.load('C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\output\\\\unet_out.pth')\n",
    "model.eval()\n",
    "\n",
    "image_no = 0\n",
    "for x,y in testLoader:\n",
    "    x = x.to(Config.DEVICE)\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    preds = torch.argmax(softmax(model(x.float())), axis = 1).detach().cpu().numpy()\n",
    "    img = np.transpose(np.array(x[0,:,:,:].to('cpu')),(1,2,0))\n",
    "    preds = np.array(preds[0,:,:])\n",
    "#     mask = np.array(y[0,:,:])\n",
    "    cv2.imwrite('C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\output\\\\Fold 3\\\\'+filenames[image_no], preds)\n",
    "    image_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fb3a497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Dice score: 0.4802336586683886\n",
      "Average IoU: 0.4202527489807674\n",
      "Average precision: 0.4885162190243142\n",
      "Average recall: 0.9770542005905056\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def iou(pred, gt):\n",
    "    intersection = np.sum((pred == 1) & (gt == 1))\n",
    "    union = np.sum((pred == 1) | (gt == 1))\n",
    "    if union == 0:\n",
    "        return 0\n",
    "    return intersection / union\n",
    "\n",
    "# ground truth masks and predictions are binary numpy arrays of shape (num_samples, height, width)\n",
    "gt_path = \"C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\Masks_800\"\n",
    "pred_path = \"C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\output\\\\Fold 3\"\n",
    "\n",
    "scores = {'filename': [], 'Dice score': [], 'IoU': [], 'precision': [], 'Recall': []}\n",
    "\n",
    "for file in os.listdir(pred_path):\n",
    "    if file.endswith('.PNG'):\n",
    "        filename = os.fsdecode(file)\n",
    "\n",
    "        y_true = cv2.imread(gt_path+'\\\\'+filename)\n",
    "        y_pred = cv2.imread(pred_path+'\\\\'+filename)\n",
    "        y_true_flat = y_true.reshape(-1)\n",
    "        y_pred_flat = y_pred.reshape(-1)\n",
    "\n",
    "        precision = precision_score(y_true_flat, y_pred_flat, average='macro')\n",
    "        recall = recall_score(y_true_flat, y_pred_flat, average='macro')\n",
    "        IoU = iou(y_pred_flat, y_true_flat)\n",
    "        dice = 2 * (y_true_flat * y_pred_flat).sum() / (y_true_flat.sum() + y_pred_flat.sum())\n",
    "        \n",
    "        scores['filename'].append(filename)\n",
    "        scores['Dice score'].append(dice)\n",
    "        scores['IoU'].append(IoU)\n",
    "        scores['precision'].append(precision)\n",
    "        scores['Recall'].append(recall)\n",
    "\n",
    "df = pd.DataFrame(scores)\n",
    "df\n",
    "average_f1_score = df['IoU'].mean()\n",
    "average_precision = df['precision'].mean()\n",
    "average_recall = df['Recall'].mean()\n",
    "average_dice = df['Dice score'].mean()\n",
    "\n",
    "print(\"Average Dice score:\", average_dice)\n",
    "print(\"Average IoU:\", average_f1_score)\n",
    "print(\"Average precision:\", average_precision)\n",
    "print(\"Average recall:\", average_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce21591",
   "metadata": {},
   "source": [
    "# Fold 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57ebcc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from UModel import UNet\n",
    "import torch\n",
    "import Config\n",
    "import dataloader\n",
    "import os\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torchvision.utils\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "filenames = []\n",
    "\n",
    "path = 'C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\output\\\\test_paths3.txt'\n",
    "\n",
    "lines = open(path,\"r\").read().split(\"\\n\")\n",
    "for line in lines:\n",
    "    filename = os.path.basename(line)\n",
    "    filenames.append(filename)\n",
    "    X_test.append(line)\n",
    "    y = 'C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\Masks\\\\'+filename\n",
    "    y_test.append(y)\n",
    "\n",
    "test_transform = A.Compose([A.Resize(Config.Input_Height, Config.Input_Width),\n",
    "                               A.Normalize(mean=(0.0), std=(1.0)),\n",
    "                               ToTensorV2()])\n",
    "testDS = dataloader.MyDataset(imagePaths=X_test, maskPaths=y_test, transform=test_transform)\n",
    "testLoader = DataLoader(testDS, shuffle=False, batch_size=1,\n",
    "                             pin_memory=Config.PIN_MEMORY)\n",
    "\n",
    "\n",
    "\n",
    "model= torch.load('C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\output\\\\unet_out.pth')\n",
    "model.eval()\n",
    "\n",
    "image_no = 0\n",
    "for x,y in testLoader:\n",
    "    x = x.to(Config.DEVICE)\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    preds = torch.argmax(softmax(model(x.float())), axis = 1).detach().cpu().numpy()\n",
    "    img = np.transpose(np.array(x[0,:,:,:].to('cpu')),(1,2,0))\n",
    "    preds = np.array(preds[0,:,:])\n",
    "#     mask = np.array(y[0,:,:])\n",
    "    cv2.imwrite('C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\output\\\\Fold 4\\\\'+filenames[image_no], preds)\n",
    "    image_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd335742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Dice score: 0.4783191301435185\n",
      "Average IoU: 0.41900449944671253\n",
      "Average precision: 0.4882859430965591\n",
      "Average recall: 0.9774490834672548\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def iou(pred, gt):\n",
    "    intersection = np.sum((pred == 1) & (gt == 1))\n",
    "    union = np.sum((pred == 1) | (gt == 1))\n",
    "    if union == 0:\n",
    "        return 0\n",
    "    return intersection / union\n",
    "\n",
    "# ground truth masks and predictions are binary numpy arrays of shape (num_samples, height, width)\n",
    "gt_path = \"C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\Masks_800\"\n",
    "pred_path = \"C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\output\\\\Fold 4\"\n",
    "\n",
    "scores = {'filename': [], 'Dice score': [], 'IoU': [], 'precision': [], 'Recall': []}\n",
    "\n",
    "for file in os.listdir(pred_path):\n",
    "    if file.endswith('.PNG'):\n",
    "        filename = os.fsdecode(file)\n",
    "\n",
    "        y_true = cv2.imread(gt_path+'\\\\'+filename)\n",
    "        y_pred = cv2.imread(pred_path+'\\\\'+filename)\n",
    "        y_true_flat = y_true.reshape(-1)\n",
    "        y_pred_flat = y_pred.reshape(-1)\n",
    "\n",
    "        precision = precision_score(y_true_flat, y_pred_flat, average='macro')\n",
    "        recall = recall_score(y_true_flat, y_pred_flat, average='macro')\n",
    "        IoU = iou(y_pred_flat, y_true_flat)\n",
    "        dice = 2 * (y_true_flat * y_pred_flat).sum() / (y_true_flat.sum() + y_pred_flat.sum())\n",
    "        \n",
    "        scores['filename'].append(filename)\n",
    "        scores['Dice score'].append(dice)\n",
    "        scores['IoU'].append(IoU)\n",
    "        scores['precision'].append(precision)\n",
    "        scores['Recall'].append(recall)\n",
    "\n",
    "df = pd.DataFrame(scores)\n",
    "df\n",
    "average_f1_score = df['IoU'].mean()\n",
    "average_precision = df['precision'].mean()\n",
    "average_recall = df['Recall'].mean()\n",
    "average_dice = df['Dice score'].mean()\n",
    "\n",
    "print(\"Average Dice score:\", average_dice)\n",
    "print(\"Average IoU:\", average_f1_score)\n",
    "print(\"Average precision:\", average_precision)\n",
    "print(\"Average recall:\", average_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae72c274",
   "metadata": {},
   "source": [
    "# Fold 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7324c1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from UModel import UNet\n",
    "import torch\n",
    "import Config\n",
    "import dataloader\n",
    "import os\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torchvision.utils\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "filenames = []\n",
    "\n",
    "path = 'C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\output\\\\test_paths4.txt'\n",
    "\n",
    "lines = open(path,\"r\").read().split(\"\\n\")\n",
    "for line in lines:\n",
    "    filename = os.path.basename(line)\n",
    "    filenames.append(filename)\n",
    "    X_test.append(line)\n",
    "    y = 'C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\Masks\\\\'+filename\n",
    "    y_test.append(y)\n",
    "\n",
    "test_transform = A.Compose([A.Resize(Config.Input_Height, Config.Input_Width),\n",
    "                               A.Normalize(mean=(0.0), std=(1.0)),\n",
    "                               ToTensorV2()])\n",
    "testDS = dataloader.MyDataset(imagePaths=X_test, maskPaths=y_test, transform=test_transform)\n",
    "testLoader = DataLoader(testDS, shuffle=False, batch_size=1,\n",
    "                             pin_memory=Config.PIN_MEMORY)\n",
    "\n",
    "\n",
    "\n",
    "model= torch.load('C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\output\\\\unet_out.pth')\n",
    "model.eval()\n",
    "\n",
    "image_no = 0\n",
    "for x,y in testLoader:\n",
    "    x = x.to(Config.DEVICE)\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    preds = torch.argmax(softmax(model(x.float())), axis = 1).detach().cpu().numpy()\n",
    "    img = np.transpose(np.array(x[0,:,:,:].to('cpu')),(1,2,0))\n",
    "    preds = np.array(preds[0,:,:])\n",
    "#     mask = np.array(y[0,:,:])\n",
    "    cv2.imwrite('C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\output\\\\Fold 5\\\\'+filenames[image_no], preds)\n",
    "    image_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb1b1e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Dice score: 0.480204175482539\n",
      "Average IoU: 0.4194617211921748\n",
      "Average precision: 0.4883720371258464\n",
      "Average recall: 0.9781633214420851\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def iou(pred, gt):\n",
    "    intersection = np.sum((pred == 1) & (gt == 1))\n",
    "    union = np.sum((pred == 1) | (gt == 1))\n",
    "    if union == 0:\n",
    "        return 0\n",
    "    return intersection / union\n",
    "\n",
    "# ground truth masks and predictions are binary numpy arrays of shape (num_samples, height, width)\n",
    "gt_path = \"C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\Masks_800\"\n",
    "pred_path = \"C:\\\\Users\\\\Ahmed Waleed\\\\Desktop\\\\Multi-class UNET\\\\Dataset\\\\output\\\\Fold 5\"\n",
    "\n",
    "scores = {'filename': [], 'Dice score': [], 'IoU': [], 'precision': [], 'Recall': []}\n",
    "\n",
    "for file in os.listdir(pred_path):\n",
    "    if file.endswith('.PNG'):\n",
    "        filename = os.fsdecode(file)\n",
    "\n",
    "        y_true = cv2.imread(gt_path+'\\\\'+filename)\n",
    "        y_pred = cv2.imread(pred_path+'\\\\'+filename)\n",
    "        y_true_flat = y_true.reshape(-1)\n",
    "        y_pred_flat = y_pred.reshape(-1)\n",
    "\n",
    "        precision = precision_score(y_true_flat, y_pred_flat, average='macro')\n",
    "        recall = recall_score(y_true_flat, y_pred_flat, average='macro')\n",
    "        IoU = iou(y_pred_flat, y_true_flat)\n",
    "        dice = 2 * (y_true_flat * y_pred_flat).sum() / (y_true_flat.sum() + y_pred_flat.sum())\n",
    "        \n",
    "        scores['filename'].append(filename)\n",
    "        scores['Dice score'].append(dice)\n",
    "        scores['IoU'].append(IoU)\n",
    "        scores['precision'].append(precision)\n",
    "        scores['Recall'].append(recall)\n",
    "\n",
    "df = pd.DataFrame(scores)\n",
    "df\n",
    "average_f1_score = df['IoU'].mean()\n",
    "average_precision = df['precision'].mean()\n",
    "average_recall = df['Recall'].mean()\n",
    "average_dice = df['Dice score'].mean()\n",
    "\n",
    "print(\"Average Dice score:\", average_dice)\n",
    "print(\"Average IoU:\", average_f1_score)\n",
    "print(\"Average precision:\", average_precision)\n",
    "print(\"Average recall:\", average_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e032bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
