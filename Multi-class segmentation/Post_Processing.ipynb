{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1aa5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from skimage.transform import hough_line, hough_line_peaks\n",
    "from skimage.feature import canny\n",
    "from skimage.draw import line\n",
    "from skimage import data\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import cv2\n",
    "from skimage import filters\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "def non_max_suppression(heatmap, window_size=3):\n",
    "    \"\"\"\n",
    "    Applies non-maximum suppression to a heatmap\n",
    "    \n",
    "    Arguments:\n",
    "    heatmap -- The input heatmap\n",
    "    window_size -- The size of the suppression window (default 3)\n",
    "    \n",
    "    Returns:\n",
    "    The coordinates of the starting point\n",
    "    \"\"\"\n",
    "    # Find local maxima\n",
    "    local_max = ndi.maximum_filter(heatmap, size=window_size, mode='constant')\n",
    "    maxima = (heatmap == local_max)\n",
    "    maxima &= (heatmap > 0)\n",
    "    \n",
    "    # Find coordinates of maxima\n",
    "    coordinates = np.column_stack(np.nonzero(maxima))\n",
    "    \n",
    "    # Select the starting point\n",
    "    starting_point = coordinates[heatmap[coordinates[:, 0], coordinates[:, 1]].argmax()]\n",
    "    \n",
    "    return starting_point\n",
    "\n",
    "def non_local_means(heatmap, h=1, sigma=1):\n",
    "    \"\"\"\n",
    "    Apply Non-local Means filtering to a heatmap\n",
    "    \n",
    "    Parameters:\n",
    "        heatmap (numpy array): The input heatmap to be filtered\n",
    "        h (float): The filter strength (smaller h = stronger filter)\n",
    "        sigma (float): The standard deviation of the Gaussian kernel\n",
    "    \n",
    "    Returns:\n",
    "        numpy array: The filtered heatmap\n",
    "    \"\"\"\n",
    "    filtered_heatmap = cv2.fastNlMeansDenoising(heatmap, h=h, templateWindowSize=3, searchWindowSize=15)\n",
    "    return filtered_heatmap\n",
    "\n",
    "def apply_erosion(heatmap, kernel_size=6):\n",
    "    \"\"\"\n",
    "    Apply erosion to a heatmap\n",
    "    \n",
    "    Parameters:\n",
    "        heatmap (numpy array): The input heatmap to be eroded\n",
    "        kernel_size (int): The size of the structuring element used for erosion\n",
    "    \n",
    "    Returns:\n",
    "        numpy array: The eroded heatmap\n",
    "    \"\"\"\n",
    "    # Define a structuring element for erosion\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    \n",
    "    # Apply erosion to the heatmap\n",
    "    eroded_heatmap = cv2.erode(heatmap, kernel)\n",
    "    \n",
    "    return eroded_heatmap\n",
    "\n",
    "\n",
    "def apply_median_filter(heatmap, kernel_size=9):\n",
    "    \"\"\"\n",
    "    Apply median filtering to a heatmap\n",
    "    \n",
    "    Parameters:\n",
    "        heatmap (numpy array): The input heatmap to be filtered\n",
    "        kernel_size (int): The size of the sliding window used for median filtering\n",
    "    \n",
    "    Returns:\n",
    "        numpy array: The filtered heatmap\n",
    "    \"\"\"\n",
    "    filtered_heatmap = cv2.medianBlur(heatmap, kernel_size)\n",
    "    return filtered_heatmap\n",
    "\n",
    "path = os.chdir('C:\\\\Users\\\\z004b1tz\\\\Desktop\\\\Master Thesis Project\\\\Multi-class UNET\\\\Dataset\\\\output\\\\erosion')\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    filename = os.fsdecode(file)\n",
    "    image = cv2.imread(filename)\n",
    "    starting_point = non_max_suppression(image)\n",
    "    print(starting_point)\n",
    "    # Group the indices by the row coordinate\n",
    "    grouped_rows = {}\n",
    "    for i, row in enumerate(rows):\n",
    "        if row not in grouped_rows:\n",
    "            grouped_rows[row] = []\n",
    "        grouped_rows[row].append(cols[i])\n",
    "\n",
    "    # Calculate the average x and y coordinates for each group of green pixels\n",
    "    coordinates = []\n",
    "    for row, cols_group in grouped_rows.items():\n",
    "        x = int(np.mean(cols_group))\n",
    "        y = int(row)\n",
    "        coordinates.append((x, y))\n",
    "    print(coordinates)\n",
    "    plt.imsave('C:\\\\Users\\\\z004b1tz\\\\Desktop\\\\Master Thesis Project\\\\Multi-class UNET\\\\Dataset\\\\output\\\\pred\\\\'+filename, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcb0419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = os.chdir('C:\\\\Users\\\\z004b1tz\\\\Desktop\\\\Master Thesis Project\\\\Multi-class UNET\\\\Dataset\\\\output\\\\erosion')\n",
    "\n",
    "# Define the colormap\n",
    "colormap = np.array([[0, 0, 0], [0, 0, 0], [255, 0, 0]])\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    filename = os.fsdecode(file)\n",
    "    image = cv2.imread(filename)\n",
    "    image = np.array(image[:,:,0])\n",
    "    # Convert the predictions to an image using the colormap\n",
    "    image = colormap[image.astype(int)].astype(np.uint8)\n",
    "\n",
    "    # Save the image\n",
    "    plt.imsave('C:\\\\Users\\\\z004b1tz\\\\Desktop\\\\Master Thesis Project\\\\Multi-class UNET\\\\Dataset\\\\output\\\\pred\\\\'+filename, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a66526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def apply_erosion(heatmap, kernel_size=15):\n",
    "    \"\"\"\n",
    "    Apply erosion to a heatmap\n",
    "    \n",
    "    Parameters:\n",
    "        heatmap (numpy array): The input heatmap to be eroded\n",
    "        kernel_size (int): The size of the structuring element used for erosion\n",
    "    \n",
    "    Returns:\n",
    "        numpy array: The eroded heatmap\n",
    "    \"\"\"\n",
    "    # Define a structuring element for erosion\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    \n",
    "    # Apply erosion to the heatmap\n",
    "    eroded_heatmap = cv2.erode(heatmap, kernel)\n",
    "    \n",
    "    return eroded_heatmap\n",
    "\n",
    "path = os.chdir('C:\\\\Users\\\\z004b1tz\\\\Desktop\\\\Master Thesis Project\\\\Multi-class UNET\\\\Dataset\\\\output\\\\predictions')\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    filename = os.fsdecode(file)\n",
    "    image = cv2.imread(filename,0)\n",
    "    retval, binary = cv2.threshold(image, 225, 255, cv2.THRESH_BINARY)\n",
    "    result = apply_erosion(binary)\n",
    "    # Save the image\n",
    "    plt.imsave('C:\\\\Users\\\\z004b1tz\\\\Desktop\\\\Master Thesis Project\\\\Multi-class UNET\\\\Dataset\\\\output\\\\erosion\\\\'+filename, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b8e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def apply_erosion(heatmap, kernel_size=15):\n",
    "    # Define a structuring element for erosion\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    \n",
    "    # Apply erosion to the heatmap\n",
    "    eroded_heatmap = cv2.erode(heatmap, kernel)\n",
    "    \n",
    "    return eroded_heatmap\n",
    "\n",
    "path = os.chdir('C:\\\\Users\\\\z004b1tz\\\\Desktop\\\\Master Thesis Project\\\\Multi-class UNET\\\\Dataset\\\\output\\\\preds')\n",
    "gt_path = 'C:\\\\Users\\\\z004b1tz\\\\Desktop\\\\Master Thesis Project\\\\ground'\n",
    "\n",
    "detected = {'filename':[], 'detected_point':[]}\n",
    "true, false = 0,0\n",
    "for file in os.listdir(path):\n",
    "    filename = os.fsdecode(file)\n",
    "    ground = filename.replace('.PNG', '.raw.csv')\n",
    "    image = cv2.imread(filename,0)\n",
    "    image = apply_erosion(image)\n",
    "    retval, binary = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cells = pd.read_csv(gt_path+'\\\\'+ground)\n",
    "    if len(cells) == len(contours):\n",
    "        true += 1\n",
    "    else:\n",
    "        false += 1\n",
    "        break\n",
    "    contours_image = cv2.drawContours(binary, contours, -1, (255,0,0), 3)\n",
    "    detected['filename'].append(filename)\n",
    "#     plt.imsave('C:\\\\Users\\\\z004b1tz\\\\Desktop\\\\Master Thesis Project\\\\Multi-class UNET\\\\Dataset\\\\output\\\\New folder\\\\'+filename,binary)\n",
    "    for contour in contours:\n",
    "        areas.append(cv2.contourArea(contour))\n",
    "        x,y,w,h = cv2.boundingRect(contour)\n",
    "#         print(x,y,w,h)\n",
    "        cv2.rectangle(contours_image,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        cv2.circle(contours_image, (x+w//2, y+h//2), 5, (255, 255, 255), -1)\n",
    "        x_detected = x+w//2\n",
    "        y_detected = y+h//2\n",
    "        point = list((x_detected, y_detected))\n",
    "        detected['detected_point'].append(point)\n",
    "    print(filename)\n",
    "    plt.imshow(contours_image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41adf390",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas\n",
    "areas_filtered = [x for x in areas if x > 10]\n",
    "print(len(areas_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcfc58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(areas_filtered)\n",
    "plt.hist(areas_filtered,bins = 300)\n",
    "plt.title('Contour areas distribution')\n",
    "plt.xlabel('Area')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5e1f78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
