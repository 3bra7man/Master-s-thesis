{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f22578e0",
   "metadata": {},
   "source": [
    "# Cross Validation using 5 folds and run the Training and Validation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f254ae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataloader\n",
    "from UModel import UNet\n",
    "import Config\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from imutils import paths\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "from torchmetrics.functional import dice\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import Early_stopping as E\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the image and mask filepaths in a sorted manner\n",
    "imagePaths = np.array(sorted(list(paths.list_images(Config.Image_dataset_dir))))\n",
    "maskPaths = np.array(sorted(list(paths.list_images(Config.Mask_dataset_dir))))\n",
    "\n",
    "# Taking out the test set and leaving the rest of the data for cross validation\n",
    "X_rest, X_test, y_rest, y_test = train_test_split(imagePaths, maskPaths, train_size=0.9, random_state=42, shuffle = True)\n",
    "\n",
    "print(\"Saving testing image paths...\")\n",
    "f = open(Config.TEST_PATHS, \"w\")\n",
    "f.write(\"\\n\".join(X_test))\n",
    "f.close()\n",
    "\n",
    "# Setting up the Kfold cross validation with 5 folds\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "index = 0\n",
    "for train_index, val_index in kf.split(X_rest, y_rest):\n",
    "    # Splitting the data into training and validation sets\n",
    "    X_train, X_val = X_rest[train_index], X_rest[val_index]\n",
    "    y_train, y_val = y_rest[train_index], y_rest[val_index]\n",
    "    \n",
    "    f = open(Config.Base_Out+'\\\\train_paths'+str(index)+'.txt', \"w\")\n",
    "    f.write(\"\\n\".join(X_train))\n",
    "    f.close()\n",
    "    \n",
    "    f = open(Config.Base_Out+'\\\\validation_paths'+str(index)+'.txt', \"w\")\n",
    "    f.write(\"\\n\".join(X_val))\n",
    "    f.close()\n",
    "    \n",
    "    # Define transformations\n",
    "    train_transform = A.Compose([A.Resize(Config.Input_Height, Config.Input_Width),\n",
    "                                 A.Normalize(mean=(0.0), std=(1.0)),\n",
    "                                 A.HorizontalFlip(p=0.5), \n",
    "                                 A.RandomRotate90(p=0.5),\n",
    "                                 ToTensorV2()])\n",
    "    val_transform = A.Compose([A.Resize(Config.Input_Height, Config.Input_Width),\n",
    "                               A.Normalize(mean=(0.0), std=(1.0)),\n",
    "                               A.VerticalFlip(p=0.5), \n",
    "                               A.RandomRotate90(p=0.5),\n",
    "                               ToTensorV2()])\n",
    "    \n",
    "    # Create the train and validation datasets\n",
    "    trainDS = dataloader.dataset(imagePaths=X_train, maskPaths=y_train, transform=train_transform)\n",
    "    valDS = dataloader.dataset(imagePaths=X_val, maskPaths=y_val, transform=val_transform)\n",
    "    print(f\"There are {len(trainDS)} samples in the training set\")\n",
    "    print(f\"There are {len(valDS)} samples in the validation set\")\n",
    "    print('************************************************')\n",
    "\n",
    "    # Create the train and validation dataloaders\n",
    "    trainLoader = DataLoader(trainDS, shuffle=True, batch_size=Config.Batch_size,\n",
    "                             pin_memory=Config.PIN_MEMORY, num_workers=os.cpu_count())\n",
    "\n",
    "    valLoader = DataLoader(valDS, shuffle=True, batch_size=Config.Batch_size,\n",
    "                           pin_memory=Config.PIN_MEMORY, num_workers=os.cpu_count())\n",
    "\n",
    "    # initialize our UNet model\n",
    "    unet = UNet(n_channels=Config.No_channels, n_classes=Config.No_classes, bilinear=False).to(Config.DEVICE)\n",
    "\n",
    "    # initialize Binary cross entropy with logit loss function and Adam optimizer\n",
    "    lossFunc = BCEWithLogitsLoss()\n",
    "    opt = Adam(unet.parameters(), lr=Config.Init_LR)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(opt, 'max', patience=10)\n",
    "    early_stopper = E.EarlyStopper(patience=10, min_delta=0.01)\n",
    "\n",
    "    # calculate steps per epoch for training, validation and test set\n",
    "    trainSteps = len(trainDS) // Config.Batch_size\n",
    "    valSteps = len(valDS) // Config.Batch_size\n",
    "\n",
    "    # initialize a dictionary to store training history\n",
    "    CE_loss = {\"train_loss\": [], \"val_loss\": []}\n",
    "    dsc_loss = {\"Dice_train\": [], \"Dice_val\": []}\n",
    "\n",
    "    # loop over epochs\n",
    "    print(\"Training the network...\")\n",
    "    startTime = time.time()\n",
    "\n",
    "    for e in tqdm(range(Config.Num_epochs)):\n",
    "        # set the model in training mode\n",
    "        unet.train()\n",
    "\n",
    "        # initialize the total training and validation loss0\n",
    "        totalTrainLoss, totalValLoss, dice_score_train, dice_score_val = 0, 0, 0, 0\n",
    "\n",
    "        # loop over the training set\n",
    "        for (i, (x, y)) in enumerate(trainLoader):\n",
    "            # send the input to the device\n",
    "            (x, y) = (x.to(Config.DEVICE), y.to(Config.DEVICE))\n",
    "\n",
    "            # perform a forward pss and calculate the training loss\n",
    "            pred = unet(x)\n",
    "            CEloss = lossFunc(pred, y)\n",
    "            dice_loss = dice(torch.sigmoid(pred), y.type(torch.int32))\n",
    "            total_loss = (1 - dice_loss) + CEloss\n",
    "\n",
    "            # first, zero out any previously accumulated gradients, then\n",
    "            # perform backpropagation, and then update model parameters\n",
    "            opt.zero_grad()\n",
    "            total_loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            # add the loss to the total training loss so far\n",
    "            totalTrainLoss += CEloss\n",
    "            dice_score_train += dice_loss\n",
    "\n",
    "        # switch off autograd\n",
    "        with torch.no_grad():\n",
    "            # set the model in evaluation mode\n",
    "            unet.eval()\n",
    "\n",
    "            # loop over the validation set\n",
    "            for (x, y) in valLoader:\n",
    "                # send the input to the device\n",
    "                (x, y) = (x.to(Config.DEVICE), y.to(Config.DEVICE))\n",
    "\n",
    "                # make the predictions and calculate the validation loss\n",
    "                pred = unet(x)\n",
    "                totalValLoss += lossFunc(pred, y)\n",
    "                dice_score_val += dice(torch.sigmoid(pred), y.type(torch.int32))\n",
    "\n",
    "        # calculate the average training and validation loss\n",
    "        avgTrainLoss = totalTrainLoss / trainSteps\n",
    "        avgValLoss = totalValLoss / valSteps\n",
    "        avgDiceTrain = dice_score_train / trainSteps\n",
    "        avgDiceVal = dice_score_val / valSteps\n",
    "        \n",
    "        # Checking the validation loss if not changing for early stopping\n",
    "        if early_stopper.early_stop(avgValLoss):\n",
    "            break\n",
    "        \n",
    "        # Adapting the learining rate based on maximized Dice Score\n",
    "        scheduler.step(avgDiceVal)\n",
    "        print(opt.state_dict()['param_groups'][0]['lr'])\n",
    "\n",
    "        # update the training history\n",
    "        CE_loss[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
    "        CE_loss[\"val_loss\"].append(avgValLoss.cpu().detach().numpy())\n",
    "        dsc_loss[\"Dice_train\"].append(avgDiceTrain.cpu().detach().numpy())\n",
    "        dsc_loss[\"Dice_val\"].append(avgDiceVal.cpu().detach().numpy())\n",
    "\n",
    "        # print the model training and validation information\n",
    "        print(\"EPOCH: {}/{}\".format(e + 1, Config.Num_epochs))\n",
    "        print(\"Train loss: {:.4f}, Validation loss: {:.4f}\".format(avgTrainLoss, avgValLoss))\n",
    "        print(\"Training Dice Score: {:.4f}% , Validation Dice Score: {:.4f}%\".format(avgDiceTrain * 100, avgDiceVal * 100))\n",
    "        del dice_score_train, dice_score_val, avgDiceTrain, avgDiceVal, totalTrainLoss, totalValLoss, avgTrainLoss, avgValLoss\n",
    "\n",
    "    # display the total time needed to perform the training\n",
    "    endTime = time.time()\n",
    "    print(\"Total time taken to train the model: {:.2f}s\".format(endTime - startTime))\n",
    "    \n",
    "    # plot the training loss\n",
    "    plt.style.use(\"ggplot\")\n",
    "    fig1 = plt.figure(figsize=[15.0,15.0])\n",
    "    ax1 = fig1.add_subplot(2, 1, 1)\n",
    "    plt.plot(CE_loss[\"train_loss\"], label=\"train_loss\")\n",
    "    plt.plot(CE_loss[\"val_loss\"], label=\"validation_loss\")\n",
    "    plt.title(\"Training Loss vs. Validation Loss\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    "    plt.savefig(os.path.sep.join([Config.Base_Out+'\\\\plots', \"CELoss\"+str(index)+\".png\"]))\n",
    "\n",
    "    plt.style.use(\"ggplot\")\n",
    "    fig1 = plt.figure(figsize=[15.0,15.0])\n",
    "    ax1 = fig1.add_subplot(2, 1, 2)\n",
    "    plt.plot(dsc_loss[\"Dice_train\"], label=\"train_dice_score\")\n",
    "    plt.plot(dsc_loss[\"Dice_val\"], label=\"validation_dice_score\")\n",
    "    plt.title(\"Training Dice Score vs. Validation Dice Score\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Dice Score\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "    plt.savefig(os.path.sep.join([Config.Base_Out+'\\\\plots', \"DiceLoss\"+str(index)+\".png\"]))\n",
    "\n",
    "    index += 1\n",
    "    # serialize the model to disk\n",
    "    torch.save(unet, Config.MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daedf39c",
   "metadata": {},
   "source": [
    "# Plotting the CE loss and dice scores for training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98754436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot the training loss\n",
    "plt.style.use(\"ggplot\")\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(2, 1, 1)\n",
    "plt.plot(CE_loss[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(CE_loss[\"val_loss\"], label=\"validation_loss\")\n",
    "plt.title(\"Training Loss vs. Validation Loss\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(Config.LOSS_PATH)\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(2, 1, 2)\n",
    "plt.plot(dsc_loss[\"Dice_train\"], label=\"train_dice_loss\")\n",
    "plt.plot(dsc_loss[\"Dice_val\"], label=\"validation_dice_loss\")\n",
    "plt.title(\"Training Dice Loss vs. Validation Dice Loss\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Dice Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(Config.DICE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0bb6e8",
   "metadata": {},
   "source": [
    "# Make predictions and save them to disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf119140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from UModel import UNet\n",
    "import Config\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.io import read_image\n",
    "import os\n",
    "import Test\n",
    "import dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from imutils import paths\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "with open(\"C:\\\\Users\\\\Jessica NT MCA\\\\Desktop\\\\MA_Abdelrahman\\\\Master Thesis Project\\\\5 layer Binary UNET\\\\Dataset\\\\output\\\\test_paths.txt\", \"r\") as f:\n",
    "    for path in f:\n",
    "        filename = os.path.basename(path)\n",
    "        X_test.append(path.rstrip('\\n'))\n",
    "        y = 'C:\\\\Users\\\\Jessica NT MCA\\\\Desktop\\\\MA_Abdelrahman\\\\Master Thesis Project\\\\5 layer Binary UNET\\\\Dataset\\\\Masks\\\\'+filename\n",
    "        y_test.append(y.rstrip('\\n'))\n",
    "f.close()\n",
    "\n",
    "X_test = np.array(sorted((X_test)))\n",
    "y_test = np.array(sorted((y_test)))\n",
    "\n",
    "test_transform = A.Compose([A.Normalize(mean=(0.0), std=(1.0)),\n",
    "                            ToTensorV2()])\n",
    "\n",
    "testDS = dataloader.dataset(imagePaths=X_test, maskPaths=y_test, transform=test_transform)\n",
    "testLoader = DataLoader(testDS, shuffle=False, batch_size=1,\n",
    "                             pin_memory=Config.PIN_MEMORY, num_workers=os.cpu_count())\n",
    "\n",
    "model = torch.load(Config.MODEL_PATH)\n",
    "Test.save_predictions_as_imgs(imagesPath = X_test, loader = testLoader, model = model, folder = Config.Base_Out+\"//predictions\", device = Config.DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79020c4",
   "metadata": {},
   "source": [
    "# Plot Predictions vs. Original image and GT mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30823803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import Config\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import Test\n",
    "import os\n",
    "\n",
    "imagePaths = open(Config.TEST_PATHS).read().strip().split(\"\\n\")\n",
    "imagePaths = np.random.choice(imagePaths, size=20)\n",
    "\n",
    "# load our model from disk and flash it to the current device\n",
    "print(\"[INFO] load up model...\")\n",
    "unet = torch.load(Config.MODEL_PATH).to(Config.DEVICE)\n",
    "\n",
    "# iterate over the randomly selected test image paths\n",
    "for path in imagePaths:\n",
    "    #make predictions and visualize the results\n",
    "    ground, pred = Test.make_predictions(unet, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8fefec",
   "metadata": {},
   "source": [
    "# Skeletenation to detect the tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3548f502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy.ndimage import generic_filter\n",
    "from skimage.morphology import medial_axis\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n",
    "# Line ends filter\n",
    "def lineEnds(P):\n",
    "    \"\"\"Central pixel and just one other must be set to be a line end\"\"\"\n",
    "    return 255 * ((P[4]==255) and np.sum(P)==510)\n",
    "\n",
    "mask_dir = 'C:\\\\Users\\\\z004b1tz\\\\Desktop\\\\Master Thesis Project\\\\Dataset\\\\Masks\\\\01827_0006_976x976_16bpp.PNG'\n",
    "img = Image.open(mask_dir)\n",
    "\n",
    "# define custom transform function\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    " \n",
    "# transform the pIL image to tensor\n",
    "# image\n",
    "img_tr = transform(img)\n",
    " \n",
    "# calculate mean and std\n",
    "mean, std = img_tr.mean([1,2]), img_tr.std([1,2])\n",
    " \n",
    "# print mean and std\n",
    "print(\"mean and std before normalize:\")\n",
    "print(\"Mean of the image:\", mean)\n",
    "print(\"Std of the image:\", std)\n",
    "\n",
    "transform_norm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# get normalized image\n",
    "img_normalized = transform_norm(img)\n",
    "\n",
    "# calculate mean and std\n",
    "mean, std = img_normalized.mean([1,2]), img_normalized.std([1,2])\n",
    " \n",
    "# print mean and std\n",
    "print('****************************************')\n",
    "print(\"mean and std after normalize:\")\n",
    "print(\"Mean of the image:\", mean)\n",
    "print(\"Std of the image:\", std)\n",
    " \n",
    "# plot the pixel values\n",
    "plt.hist(img_normalized.ravel(), bins=50, density=True)\n",
    "plt.xlabel(\"pixel values\")\n",
    "plt.ylabel(\"relative frequency\")\n",
    "plt.title(\"distribution of pixels\")\n",
    "# # Skeletonize\n",
    "# skel = (medial_axis(img)*255).astype('uint8')\n",
    "# skel\n",
    "# # Find line ends\n",
    "# result = generic_filter(skel, lineEnds, (3, 3))\n",
    "# result = Image.fromarray(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39ae152",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pd.DataFrame(tip, columns = ['path'])\n",
    "mask = pd.DataFrame(mask, columns = ['path'])\n",
    "path = pd.concat([mask, image]).drop_duplicates(keep=False)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d547aa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import dataloader\n",
    "from UModel import UNet\n",
    "import Config\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as T\n",
    "from imutils import paths\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "from torchmetrics.functional import dice\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import Early_stopping as E\n",
    "\n",
    "\n",
    "imagePaths = ['C:\\\\Users\\\\lenovo\\\\Desktop\\\\Master Thesis Project\\\\Dataset\\\\Images\\\\01824_0000_976x976_16bpp.PNG',\n",
    "             'C:\\\\Users\\\\lenovo\\\\Desktop\\\\Master Thesis Project\\\\Dataset\\\\Images\\\\01824_0001_976x976_16bpp.PNG',\n",
    "             'C:\\\\Users\\\\lenovo\\\\Desktop\\\\Master Thesis Project\\\\Dataset\\\\Images\\\\01828_0000_1952x1952_16bpp.PNG']\n",
    "\n",
    "maskPaths = ['C:\\\\Users\\\\lenovo\\\\Desktop\\\\Master Thesis Project\\\\Dataset\\\\Mask\\\\01824_0000_976x976_16bpp.PNG',\n",
    "            'C:\\\\Users\\\\lenovo\\\\Desktop\\\\Master Thesis Project\\\\Dataset\\\\Mask\\\\01824_0001_976x976_16bpp.PNG',\n",
    "            'C:\\\\Users\\\\lenovo\\\\Desktop\\\\Master Thesis Project\\\\Dataset\\\\Mask\\\\01828_0000_1952x1952_16bpp.PNG']\n",
    "\n",
    "# img_trans = T.Compose([T.Resize(976),T.ToTensor()])\n",
    "# mask_trans = T.Compose([T.Resize(976)])\n",
    "\n",
    "trainDS = dataloader.dataset(imagePaths=imagePaths, maskPaths=maskPaths)\n",
    "trainLoader = DataLoader(trainDS, shuffle=True, batch_size=1,\n",
    "                        pin_memory=Config.PIN_MEMORY, num_workers=os.cpu_count())\n",
    "\n",
    "unet = UNet(n_channels=3, n_classes=3, bilinear=False).to(Config.DEVICE)\n",
    "\n",
    "for e in tqdm(range(5)):\n",
    "    unet.train()\n",
    "\n",
    "        \n",
    "    for (i, (x, y)) in enumerate(trainLoader):\n",
    "            # send the input to the device\n",
    "        (x, y) = (x.to(Config.DEVICE), y.to(Config.DEVICE))\n",
    "\n",
    "            # perform a forward pss and calculate the training loss\n",
    "        pred = unet(x)\n",
    "\n",
    "        loss = CrossEntropyLoss()\n",
    "\n",
    "        CE_loss = loss(pred, y)\n",
    "            \n",
    "        print('The Shape of the network input is: {}'.format(x.shape))\n",
    "        print('The Shape of the target is: {}'.format(y.shape))\n",
    "        print('The Shape of the network output is: {}'.format(pred.shape))\n",
    "        print(CE_loss)\n",
    "        print('**********************************************************')\n",
    "torch.save(unet.state_dict(), 'C:\\\\Users\\\\lenovo\\\\Desktop\\\\Master Thesis Project\\\\unet.pth')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80847373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import Test\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "imagePaths = ['C:\\\\Users\\\\lenovo\\\\Desktop\\\\Master Thesis Project\\\\Dataset\\\\Images\\\\01825_0000_976x976_16bpp.PNG']\n",
    "\n",
    "img = cv2.imread(imagePaths[0])\n",
    "img = np.transpose(img, (2,0,1))\n",
    "\n",
    "image = np.expand_dims(img, 0)\n",
    "\n",
    "unet = torch.load_state_dict('C:\\\\Users\\\\lenovo\\\\Desktop\\\\Master Thesis Project\\\\unet.pth')\n",
    "\n",
    "unet.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2539a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Config\n",
    "import os\n",
    "\n",
    "for index in range(5):\n",
    "    path = os.path.sep.join([Config.Base_Out+'\\\\plots', \"DiceLoss\"+str(index)+\".png\"])\n",
    "    print(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f356a88f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
