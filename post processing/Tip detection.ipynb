{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d6e6663",
   "metadata": {},
   "source": [
    "# Hough lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc7707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tip_detection import hough_lines_image, skeletonize\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "path = os.chdir('C:\\\\Users\\\\z004b1tz\\\\Desktop\\\\Master Thesis Project\\\\Binary segmentation\\\\Dataset\\\\output\\\\Skeletonized')\n",
    "ground_truth_path = 'C:\\\\Users\\\\z004b1tz\\\\Desktop\\\\Master Thesis Project\\\\Binary segmentation\\\\Dataset\\\\output\\\\predictions\\\\predictions\\\\'\n",
    "\n",
    "final = []\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith('.PNG'):\n",
    "        filename = os.fsdecode(file)\n",
    "        ground = filename.replace('.PNG', '.raw.csv')\n",
    "        image = cv2.imread(filename)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        lines = cv2.HoughLinesP(gray, rho=1, theta=np.pi/180, threshold=30, minLineLength=20, maxLineGap=60)\n",
    "    \n",
    "        for points in lines:\n",
    "            # Extracted points nested in the list\n",
    "            x1,y1,x2,y2=points[0]\n",
    "            # Draw the lines joing the points On the original image\n",
    "            cv2.line(image,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "        \n",
    "        cells = pd.read_csv(ground_truth_path+ground, header=None , engine = 'python')\n",
    "        gt_points = []\n",
    "        for idx,row in cells.iterrows():\n",
    "            x_start = row.iloc[0]\n",
    "            y_start = row.iloc[1]\n",
    "            x_end = row.iloc[2]\n",
    "            y_end = row.iloc[3]\n",
    "            gt_points.append([x_start, y_start])\n",
    "\n",
    "        # get starting points of detected lines\n",
    "        detected_points = []\n",
    "        for line in lines:\n",
    "            detected_points.append([line[0][0], line[0][1]])\n",
    "            detected_points.append([line[0][2], line[0][3]])\n",
    "\n",
    "        # calculate error between detected points and ground truth\n",
    "        distance_errors = []\n",
    "        for point in detected_points:\n",
    "            for gt_point in gt_points:\n",
    "                distance_error = np.sqrt((point[0] - gt_point[0]) ** 2 + (point[1] - gt_point[1]) ** 2)\n",
    "                distance_errors.append(distance_error)\n",
    "\n",
    "        # remove duplicates from errors list\n",
    "        errors = list(set(distance_errors))\n",
    "        # sort errors in ascending order\n",
    "        errors.sort()\n",
    "\n",
    "        err = []\n",
    "        # get the number of errors with the minimum error\n",
    "        num_of_detected_points_with_min_errors = len(gt_points)\n",
    "        detected_points_with_min_errors = []\n",
    "        angle_errors = []\n",
    "        for gt_point in gt_points:\n",
    "            for point in detected_points:\n",
    "                error = np.sqrt((point[0] - gt_point[0]) ** 2 + (point[1] - gt_point[1]) ** 2)\n",
    "                detected_angle = math.atan2(min_point[1], min_point[0])\n",
    "                angle_error = round(abs(detected_angle - gt_angle),4)\n",
    "                angle_errors.append(angle_error)\n",
    "                err.append(error)\n",
    "                detected_points_with_min_errors.append(point)\n",
    "                detected_points.remove(point)\n",
    "\n",
    "        result = {\n",
    "            'file_name': filename,\n",
    "            'ground_truth_points': gt_points,\n",
    "            'detected_points_with_min_errors': detected_points_with_min_errors,\n",
    "            'distance_error': err,\n",
    "            'angle_error' : angle_errors\n",
    "        }\n",
    "        final.append(result)\n",
    "\n",
    "        hough_lines_image(os.path.join(path, filename), os.path.join(path, ground))\n",
    "        print(result)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7414c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(final)\n",
    "mean_distance_error = np.mean(df['distance_error'].apply(lambda x: np.mean(x)))\n",
    "print(mean_distance_error*(20/976))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278338e9",
   "metadata": {},
   "source": [
    "# Detect the connected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248e0295",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tip_detection import tip_detector_right\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = 'C:\\\\Users\\\\z004b1tz\\\\Desktop\\\\Master Thesis Project\\\\5 Layer Binary UNET\\\\Dataset\\\\output\\\\predictions\\\\predictions 700x700'\n",
    "\n",
    "result = {'filename':[], 'detected_points':[]} \n",
    "\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith('.PNG'):\n",
    "        filename = os.fsdecode(file)\n",
    "        ground = filename.replace('.PNG', '.raw.csv')\n",
    "        _, points = tip_detector_right(path+'\\\\'+filename)\n",
    "        result['filename'].append(ground)\n",
    "        result['detected_points'].append(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435c0d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b08fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {i: [] for i in df['filename'].unique()}\n",
    "df.apply(lambda x: d[x[0]].append(x[1]), axis=1)\n",
    "d = {key: value for key, value in d.items() if value[0]}\n",
    "final = list(zip(*list(d.items())))\n",
    "\n",
    "dic = {'filenames': final[0], 'detected_points': final[1]}\n",
    "df2 = pd.DataFrame(dic)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3275ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "true, false = 0,0\n",
    "\n",
    "for file in df2['filenames']:\n",
    "    cells = pd.read_csv('C:\\\\Users\\\\z004b1tz\\\\Desktop\\\\Master Thesis Project\\\\ground\\\\'+file, header=None , engine = 'python')\n",
    "    if len(cells) == len(df2.loc[df2[\"filenames\"] == file, \"detected_points\"].iloc[0]):\n",
    "        true += 1\n",
    "    else:\n",
    "        false += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494bd34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "true/(false+true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40111b02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path_to_ground_truth = 'C:\\\\Users\\\\z004b1tz\\\\Desktop\\\\Master Thesis Project\\\\ground'\n",
    "\n",
    "def calculate_errors(ground_truth_points, detected_points):\n",
    "    # Calculate the errors\n",
    "    mse = np.sqrt(np.mean((ground_truth_points - detected_points)**2))\n",
    "    mae = np.mean(np.abs(ground_truth_points - detected_points))\n",
    "    if len(ground_truth_points.shape) == 1:\n",
    "        manhattan = np.mean(np.abs(ground_truth_points - detected_points))\n",
    "    else:\n",
    "        manhattan = np.mean(np.sum(np.abs(ground_truth_points - detected_points), axis=1))\n",
    "    return [mse, mae, manhattan]\n",
    "\n",
    "\n",
    "error = {'filename':[], 'error':[]}\n",
    "for i, row in df.iterrows():\n",
    "    # Get the filename and detected points\n",
    "    filename = row['filename']\n",
    "    detected_points = row['detected_points']\n",
    "    num_detected_points = len(detected_points)\n",
    "    min_errors = [float('inf')] * num_detected_points\n",
    "\n",
    "    # Read the ground truth csv file\n",
    "    ground_truth = os.path.join(path_to_ground_truth, filename)\n",
    "    cells = pd.read_csv(ground_truth, header=None, engine='python')\n",
    "    errors = [[] for _ in range(num_detected_points)]\n",
    "    for idx, row in cells.iterrows():\n",
    "        ground_truth_point = np.array([row.iloc[0], row.iloc[1]])\n",
    "        for j, detected_point in enumerate(detected_points):\n",
    "            error = calculate_errors(ground_truth_point, np.array(detected_point))\n",
    "            for k in range(len(error)):\n",
    "                if error[k] < min_errors[j]:\n",
    "                    min_errors[j] = error[k]\n",
    "                errors[j].append(error[k])\n",
    "    print(filename)\n",
    "    print(\"Errors:\", errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f777c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "path = 'C:\\\\Users\\\\z004b1tz\\\\Desktop\\\\Master Thesis Project\\\\Multi-class UNET\\\\Dataset\\\\output\\\\erosion\\\\01840_0025_976x976_16bpp.PNG'\n",
    "\n",
    "image = cv2.imread(path)\n",
    "\n",
    "_, thresh = cv2.threshold(image,128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "print(np.unique(thresh))\n",
    "plt.imshow(thresh, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22f64d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
